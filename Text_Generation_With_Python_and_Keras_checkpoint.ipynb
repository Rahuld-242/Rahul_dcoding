{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahuld-242/Rahul_dcoding/blob/main/Text_Generation_With_Python_and_Keras_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834cc0bb",
      "metadata": {
        "id": "834cc0bb"
      },
      "source": [
        "## Part One: The Data\n",
        "\n",
        "* Import Main Libraries\n",
        "* Importing Text\n",
        "* Understanding Characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3cae7008",
      "metadata": {
        "id": "3cae7008"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd36335c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd36335c",
        "outputId": "6c5e2b1a-3155-45ea-bb2f-5545b062512c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "560a2541",
      "metadata": {
        "id": "560a2541"
      },
      "outputs": [],
      "source": [
        "path_to_file=\"shakespeare.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "869fe86a",
      "metadata": {
        "id": "869fe86a"
      },
      "outputs": [],
      "source": [
        "text=open(path_to_file,'r').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "780433f0",
      "metadata": {
        "id": "780433f0"
      },
      "outputs": [],
      "source": [
        "#print(text[140500:141800])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9aafb29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9aafb29",
        "outputId": "4166a83c-cfd6-485b-b1f5-f228aac4583a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vocab=sorted(set(text))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f97cb50d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97cb50d",
        "outputId": "cd6290f7-0b94-45db-9614-a26b91589d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd43cec",
      "metadata": {
        "id": "abd43cec"
      },
      "source": [
        "## Part Two: Text Processing\n",
        "\n",
        "* Vectorize the text\n",
        "* Create encoding dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5362a399",
      "metadata": {
        "id": "5362a399"
      },
      "outputs": [],
      "source": [
        "#for pair in enumerate(vocab):\n",
        "#    print(pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fc6c1726",
      "metadata": {
        "id": "fc6c1726"
      },
      "outputs": [],
      "source": [
        "char_to_ind={char: ind for ind,char in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a39cd2e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a39cd2e7",
        "outputId": "76f21d5f-2e41-49d7-c1f9-d936be32de3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "char_to_ind['H']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c00bf7a4",
      "metadata": {
        "id": "c00bf7a4"
      },
      "outputs": [],
      "source": [
        "ind_to_char=np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7b9538ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7b9538ba",
        "outputId": "77f64616-6022-477e-f1ff-845d26d12b24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'H'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ind_to_char[33]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bebed278",
      "metadata": {
        "id": "bebed278"
      },
      "outputs": [],
      "source": [
        "encoded_text=np.array([char_to_ind[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ae8950d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae8950d0",
        "outputId": "3bbfe4f1-ec5f-42c4-bc3c-e112c18041a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "encoded_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f5123691",
      "metadata": {
        "id": "f5123691"
      },
      "outputs": [],
      "source": [
        "sample=text[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2c918037",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2c918037",
        "outputId": "df906867-0cdc-4827-99ed-3b5ea45aefd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "60aa476c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60aa476c",
        "outputId": "464a9e1e-0d90-4a5c-979c-114b11cc336d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "encoded_text[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a9b1939",
      "metadata": {
        "id": "8a9b1939"
      },
      "source": [
        "## Part Three: Creating Batches\n",
        "\n",
        "* Understand text sequences\n",
        "* Use Tensorflow datasets to generate batches\n",
        "* Shuffle batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9578885c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9578885c",
        "outputId": "3e9efa0f-b80f-4be2-ed6a-70dde94c884f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1bd38549",
      "metadata": {
        "id": "1bd38549"
      },
      "outputs": [],
      "source": [
        "line=\"From fairest creatures we desire increase\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6b73dce3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b73dce3",
        "outputId": "af6c7fbe-8d7e-44c6-dea5-9b5b9b4c766b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4546ae7d",
      "metadata": {
        "id": "4546ae7d"
      },
      "outputs": [],
      "source": [
        "lines=\"\"\"\n",
        " From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8e35eb33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e35eb33",
        "outputId": "a62510de-5248-4de5-d205-7b2ab7978d25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "520cefa3",
      "metadata": {
        "id": "520cefa3"
      },
      "outputs": [],
      "source": [
        "seq_len=120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "25d75506",
      "metadata": {
        "id": "25d75506"
      },
      "outputs": [],
      "source": [
        "total_num_seq=len(text)//(seq_len+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "05df5b50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05df5b50",
        "outputId": "78fc0e2f-7b53-409c-c4b2-8e53548f032b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "total_num_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1903b33d",
      "metadata": {
        "id": "1903b33d"
      },
      "outputs": [],
      "source": [
        "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8bb1b212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bb1b212",
        "outputId": "765b907f-487c-4177-c446-caab41d80f42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "type(char_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "be3dc4bc",
      "metadata": {
        "id": "be3dc4bc"
      },
      "outputs": [],
      "source": [
        "#for item in char_dataset.take(500):\n",
        "#    print(ind_to_char[item.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b99604e6",
      "metadata": {
        "id": "b99604e6"
      },
      "outputs": [],
      "source": [
        "sequences=char_dataset.batch(seq_len+1,drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e2a4c73a",
      "metadata": {
        "id": "e2a4c73a"
      },
      "outputs": [],
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt=seq[:-1]\n",
        "    target_txt=seq[1:]\n",
        "    return input_txt, target_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "28b7e351",
      "metadata": {
        "id": "28b7e351"
      },
      "outputs": [],
      "source": [
        "dataset=sequences.map(create_seq_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a4427c4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4427c4c",
        "outputId": "c9c03d62-196f-42a7-a09d-004a9c98501d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ],
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
        "    print(\"\\n\")\n",
        "    print(target_txt.numpy())\n",
        "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f36a3852",
      "metadata": {
        "id": "f36a3852"
      },
      "outputs": [],
      "source": [
        "batch_size=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c044577b",
      "metadata": {
        "id": "c044577b"
      },
      "outputs": [],
      "source": [
        "buffer_size=10000\n",
        "dataset=dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2f4cb006",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f4cb006",
        "outputId": "b44e1335-88db-4c9f-d563-6bfb63f947f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b37b009",
      "metadata": {
        "id": "5b37b009"
      },
      "source": [
        "## Part Four: Creating the Model\n",
        "\n",
        "* Set up loss function\n",
        "* Create Model\n",
        "  * Embedding\n",
        "  * GRU\n",
        "  * Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0b259a97",
      "metadata": {
        "id": "0b259a97"
      },
      "outputs": [],
      "source": [
        "vocab_size=len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f5983504",
      "metadata": {
        "id": "f5983504"
      },
      "outputs": [],
      "source": [
        "embed_dim=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "08343a39",
      "metadata": {
        "id": "08343a39"
      },
      "outputs": [],
      "source": [
        "rnn_neurons=1026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5b40465a",
      "metadata": {
        "id": "5b40465a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "ea3efae5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea3efae5",
        "outputId": "278577e7-8d9c-4021-b68f-e938e30f82c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Standalone usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    >>> y_true = [[[ 0,  2],\n",
            "    ...            [-1, -1]],\n",
            "    ...           [[ 0,  2],\n",
            "    ...            [-1, -1]]]\n",
            "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
            "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
            "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
            "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
            "    ...   y_true, y_pred, ignore_class=-1)\n",
            "    >>> loss.numpy()\n",
            "    array([[[2.3841855e-07, 2.3841855e-07],\n",
            "            [0.0000000e+00, 0.0000000e+00]],\n",
            "           [[2.3841855e-07, 6.9314730e-01],\n",
            "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "      y_true: Ground truth values.\n",
            "      y_pred: The predicted values.\n",
            "      from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "        default, we assume that `y_pred` encodes a probability distribution.\n",
            "      axis: Defaults to -1. The dimension along which the entropy is\n",
            "        computed.\n",
            "      ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "        loss computation. This is useful, for example, in segmentation\n",
            "        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n",
            "        maps. By default (`ignore_class=None`), all classes are considered.\n",
            "    \n",
            "    Returns:\n",
            "      Sparse categorical crossentropy loss value.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(sparse_categorical_crossentropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "dd1339f0",
      "metadata": {
        "id": "dd1339f0"
      },
      "outputs": [],
      "source": [
        "#default from_logits=False\n",
        "#Need to create function to change from_logits to true\n",
        "\n",
        "def sparse_cat_loss(y_true, y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "169fd73a",
      "metadata": {
        "id": "169fd73a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f8a7886c",
      "metadata": {
        "id": "f8a7886c"
      },
      "outputs": [],
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model=Sequential()\n",
        "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))\n",
        "\n",
        "    model.compile('adam',loss=sparse_cat_loss)\n",
        "\n",
        "    return model\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0a1e87c4",
      "metadata": {
        "id": "0a1e87c4"
      },
      "outputs": [],
      "source": [
        "model=create_model(vocab_size=vocab_size, embed_dim=embed_dim, rnn_neurons=rnn_neurons, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "14768a15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14768a15",
        "outputId": "3e371fc5-6402-4bb7-913d-fc371c4acfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c949756",
      "metadata": {
        "id": "7c949756"
      },
      "source": [
        "## Part Five: Training the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "952cd021",
      "metadata": {
        "id": "952cd021"
      },
      "outputs": [],
      "source": [
        "#This is to test if the model is running correctly\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  example_batch_predictions=model(input_example_batch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58vP-gFQM3KG",
        "outputId": "280fb22c-08fa-499c-d32f-789b261bb2e3"
      },
      "id": "58vP-gFQM3KG",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
              "array([[ 0.00299996,  0.0021466 ,  0.00267193, ...,  0.00899008,\n",
              "         0.00821382, -0.00268497],\n",
              "       [ 0.00333127, -0.00269304, -0.00878132, ...,  0.00670156,\n",
              "         0.00305085,  0.00102584],\n",
              "       [-0.00235063,  0.00098842,  0.00018135, ...,  0.00839527,\n",
              "         0.00288711,  0.00708124],\n",
              "       ...,\n",
              "       [ 0.00342015,  0.00124391,  0.00324163, ..., -0.00253288,\n",
              "         0.00221732,  0.00253737],\n",
              "       [ 0.00494753,  0.00506862,  0.00203646, ..., -0.00064197,\n",
              "         0.00310355, -0.00424707],\n",
              "       [ 0.00758349,  0.00309199,  0.00543094, ..., -0.00076241,\n",
              "        -0.00216081,  0.00024673]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices=tf.random.categorical(example_batch_predictions[0],num_samples=1)"
      ],
      "metadata": {
        "id": "TdzliZY2M98D"
      },
      "id": "TdzliZY2M98D",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices=tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "vV4ncJUnN4T_"
      },
      "id": "vV4ncJUnN4T_",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char[sampled_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7NAI3Q0OEbm",
        "outputId": "496b66c1-1393-40be-be8a-4fe1b2d29a1f"
      },
      "id": "M7NAI3Q0OEbm",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['|', 'K', 'J', '_', ')', 'K', ' ', 'i', '8', 'X', 'n', 'd', 'p',\n",
              "       '-', 'c', 'h', 'R', 'b', '\"', 'M', 'F', 'q', '\\n', '&', '4', '<',\n",
              "       '1', 'G', 'H', 'q', 'c', ')', '|', 'v', '5', 'A', '(', '4', '!',\n",
              "       'z', 'b', '-', 'D', 'q', '`', 'B', 'd', '8', '[', 'a', 'e', '&',\n",
              "       '!', '-', '\\n', 'F', ':', 'J', 'U', 'g', 'V', \"'\", '5', '|', 'k',\n",
              "       'l', 'i', '_', '7', 'C', 'U', '\"', 'p', 'w', 'J', 'G', '}', 'B',\n",
              "       'N', 'n', 'k', 'q', ']', 'P', 'A', '!', 'r', '4', '\"', 'n', '[',\n",
              "       'F', '-', 'z', '0', 'o', 'h', 'O', 'r', 'K', 'q', 'T', 'O', 'k',\n",
              "       '\\n', 'x', '\"', 'P', ' ', 'A', '?', '5', 'A', '4', 'l', ']', '7',\n",
              "       \"'\", '5', 'B'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=30"
      ],
      "metadata": {
        "id": "um8Z6J5_OHzp"
      },
      "id": "um8Z6J5_OHzp",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "E8GIuakXOLma",
        "outputId": "1b56182c-c646-438a-9001-23bf9ab30aa3"
      },
      "id": "E8GIuakXOLma",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "  9/351 [..............................] - ETA: 48:12 - loss: 4.8959"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-e3a8c008565b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part Six: Generating Text"
      ],
      "metadata": {
        "id": "XNUWpBfZOsMX"
      },
      "id": "XNUWpBfZOsMX"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "vWsQL6W-OPTX"
      },
      "id": "vWsQL6W-OPTX",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
        "\n",
        "model.load_weights('shakespeare_gen.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "IL90GJVuQDSA"
      },
      "id": "IL90GJVuQDSA",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3gHxG9eQNkZ",
        "outputId": "9bf7333d-b01c-4d22-bfd8-4dde3d7093d8"
      },
      "id": "F3gHxG9eQNkZ",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
        "  num_generate=gen_size\n",
        "\n",
        "  input_eval=[char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated=[]\n",
        "\n",
        "  temperature=temp\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions=model(input_eval)\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "    predictions=predictions/temperature\n",
        "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "    input_eval=tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed+\"\".join(text_generated))"
      ],
      "metadata": {
        "id": "-BS_DDyLQ43D"
      },
      "id": "-BS_DDyLQ43D",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"JULIET\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0KuV7QUSHBr",
        "outputId": "0fa026ed-6f89-4662-dd8f-5995b69b2040"
      },
      "id": "c0KuV7QUSHBr",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JULIETES. O, he is worse.\n",
            "  EUCHEST. There is no thinking, but for otherwise; grant\n",
            "    again.\n",
            "  PLADENBEALLES. No, 'Beasol!\n",
            "  My friend, where is that, that her womb for Rome?\n",
            "  HOLOFERNES. O, madam, 'tis a bable Protcul\n",
            "    Say you have scope together arm'd and keep'd;\n",
            "    You know, my sole will come in to my colour.\n",
            "  FIRST GENTLEMAN. Yes is not now propp'd on's day to breeding\n",
            "    the remembrance of it and torture. Katherinate in this;\n",
            "    For secure thou art wisdom! Lord, how you behinde.\n",
            "  PETRUCHIO. Friend Louseur come to bed.\n",
            "  ANTONIO. Either too wildly,\n",
            "    There thy dwelling men may cam Letrous Stanley;\n",
            "    Our dull dancing chamberlain, that being done,\n",
            "    Yet with Sir Toby and lordship were going.\n",
            "  JULIA. Sir, a gentleman, I'm sure so wisely; I\n",
            "    Wise a fool's hearing.\n",
            "  GONZALO. Think'st, sir?\n",
            "  SIR TOBY. Marry, I think, i' th' matter of his father.\n",
            "  CALIBAN. I scarce be black is like the honey.\n",
            "  RODIO. You had already you a bag counterfeitly\n",
            "    knew her]  too!\n",
            "    Make w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODj-zUQpSWCi"
      },
      "id": "ODj-zUQpSWCi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}